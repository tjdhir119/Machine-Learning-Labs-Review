{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa3bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c82b9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = 1/(1+np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e91b2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_tmp = np.arange(-10,11)\n",
    "# y = sigmoid(z_tmp)\n",
    "# np.set_printoptions(precision=3) \n",
    "# print(np.c_[z_tmp, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130316d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize = (5,3))\n",
    "# ax.plot(z_tmp, y, c=\"r\")\n",
    "# ax.set_title(\"Sigmoid function\")\n",
    "# ax.set_ylabel('sigmoid(z)')\n",
    "# ax.set_xlabel('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91ec578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59de0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b, *argv):\n",
    "    m, n = X.shape\n",
    "    loss_sum = 0\n",
    "    cost = 0.0\n",
    "    z_wb = 0\n",
    "    for i in range(m):\n",
    "        #for j in range(n):\n",
    "        z_wb += (np.dot(X[i], w) + b)\n",
    "        \n",
    "        f_wb = sigmoid(z_wb)\n",
    "        loss = -y[i]*np.log(f_wb)-(1-y[i])*np.log(1-f_wb)\n",
    "        loss_sum += loss\n",
    "    cost = (1/m)*loss_sum\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6d904eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599452"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = X_train.shape\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "cost = compute_cost(X_train, y_train, initial_w, initial_b)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df568619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.666666666676065"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_w = np.array([0.2, 0.2])\n",
    "test_b = -24.\n",
    "cost = compute_cost(X_train, y_train, test_w, test_b)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df47e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b, *argv):\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "    z_wb = 0\n",
    "    for i in range(m):\n",
    "        z_wb += (np.dot(X[i], w) + b)\n",
    "        f_wb = sigmoid(z_wb)\n",
    "        err = f_wb - y[i]\n",
    "        dj_db += err\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += err * X[i, j]\n",
    "    dj_dw /= m\n",
    "    dj_db /= m    \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aedc76dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w and b (zeros):0.0\n",
      "dj_dw at initial w and b (zeros):[-0.25, -0.16666666666666666]\n"
     ]
    }
   ],
   "source": [
    "dj_db, dj_dw = compute_gradient(X_train, y_train, initial_w, initial_b)\n",
    "print(f'dj_db at initial w and b (zeros):{dj_db}' )\n",
    "print(f'dj_dw at initial w and b (zeros):{dj_dw.tolist()}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8309cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at test w and b: -0.49999999999671535\n",
      "dj_dw at test w and b: [-0.9999999999983578, -0.8333333333284063]\n"
     ]
    }
   ],
   "source": [
    "test_w = np.array([ 0.2, -0.5])\n",
    "test_b = -24\n",
    "dj_db, dj_dw  = compute_gradient(X_train, y_train, test_w, test_b)\n",
    "\n",
    "print('dj_db at test w and b:', dj_db)\n",
    "print('dj_dw at test w and b:', dj_dw.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49476cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, b, cost_function, gradient_function, alpha, num_iters, lambda_):\n",
    "    m = len(X)\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "#     w = copy.deepcopy(w_in)\n",
    "#     b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_db, dj_dw = gradient_function(X, y, w, b, lambda_)\n",
    "        \n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db        \n",
    "        \n",
    "        if i<100000:\n",
    "            J_history.append(cost_function(X, y, w, b, lambda_))\n",
    "            \n",
    "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
    "            w_history.append(w)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "            \n",
    "    return w, b, J_history, w_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "073a5df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00082978  0.00220324] -8\n",
      "Iteration    0: Cost    19.99   \n",
      "Iteration 1000: Cost    12.55   \n",
      "Iteration 2000: Cost     5.13   \n",
      "Iteration 3000: Cost     0.38   \n",
      "Iteration 4000: Cost     0.13   \n",
      "Iteration 5000: Cost     0.10   \n",
      "Iteration 6000: Cost     0.09   \n",
      "Iteration 7000: Cost     0.08   \n",
      "Iteration 8000: Cost     0.08   \n",
      "Iteration 9000: Cost     0.07   \n",
      "Iteration 9999: Cost     0.07   \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "initial_w = 0.01 * (np.random.rand(2) - 0.5)\n",
    "initial_b = -8\n",
    "print(initial_w, initial_b)\n",
    "# Some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 0.001\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_train ,y_train, initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae201b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
